{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP9ECjtQtzUFKrzTTYSzCYL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"611aaf35c5cb422da9faf1905de9423f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_862318de4c4a4958868d213650e92708","IPY_MODEL_d3a78e4b701148b0aa8215a9db3c6989","IPY_MODEL_d8a074de98cd44dd8a4bf17a127119c1"],"layout":"IPY_MODEL_ee536f94084a495ab1763ed6648210d8"}},"862318de4c4a4958868d213650e92708":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_86fedfe45fa24c33b03fe21507cd8595","placeholder":"​","style":"IPY_MODEL_f7ae8291d29b460eaae3a9cc803b2f5e","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"d3a78e4b701148b0aa8215a9db3c6989":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd6708d7d93e49b0924ac65cccf5429d","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b291948b79a541bda4777a6052274222","value":231508}},"d8a074de98cd44dd8a4bf17a127119c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_859375b65f98404c8d2135101a8724e0","placeholder":"​","style":"IPY_MODEL_9699a5c54eef405b8845b2211ce728db","value":" 232k/232k [00:00&lt;00:00, 7.38MB/s]"}},"ee536f94084a495ab1763ed6648210d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86fedfe45fa24c33b03fe21507cd8595":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7ae8291d29b460eaae3a9cc803b2f5e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd6708d7d93e49b0924ac65cccf5429d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b291948b79a541bda4777a6052274222":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"859375b65f98404c8d2135101a8724e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9699a5c54eef405b8845b2211ce728db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6b9c98c40ce048638c8072aa2b1527fc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fef4e54403f54189b2d640669f93a098","IPY_MODEL_5251319c95924f239ee8374102f92999","IPY_MODEL_0d984ac7a0244adb927f0b0a15397ccf"],"layout":"IPY_MODEL_cdb004b884fa4895a682a40a6bb5f036"}},"fef4e54403f54189b2d640669f93a098":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7539f9550a584d8593b3f049df67738f","placeholder":"​","style":"IPY_MODEL_906962d5394a4f768addfc1d06169307","value":"Downloading (…)okenizer_config.json: 100%"}},"5251319c95924f239ee8374102f92999":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd325f439cc84ea29d95463d5e683d85","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f3b1dfc6abce4de5b037d05bb8ab4eb6","value":28}},"0d984ac7a0244adb927f0b0a15397ccf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e22524ac2e874a68aef0968ebebd41c8","placeholder":"​","style":"IPY_MODEL_d3691e8da91d48b58fc3176aaa2f466e","value":" 28.0/28.0 [00:00&lt;00:00, 985B/s]"}},"cdb004b884fa4895a682a40a6bb5f036":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7539f9550a584d8593b3f049df67738f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"906962d5394a4f768addfc1d06169307":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd325f439cc84ea29d95463d5e683d85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3b1dfc6abce4de5b037d05bb8ab4eb6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e22524ac2e874a68aef0968ebebd41c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3691e8da91d48b58fc3176aaa2f466e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4b94eb66bf347e1a85703dbe1f03502":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_938fbc2b81e74ac6a5c4246b5587a5f2","IPY_MODEL_67d90f623adf47a3990e2fee1a27ec20","IPY_MODEL_a49968c85f184e799b3e01713d810ca0"],"layout":"IPY_MODEL_24fb8a175a834cc28cc76414f1479ead"}},"938fbc2b81e74ac6a5c4246b5587a5f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_37d9ed7a399448328942e2e83d4cdfe1","placeholder":"​","style":"IPY_MODEL_470d2ba87bd54f3f850aa3c75becf258","value":"Downloading (…)lve/main/config.json: 100%"}},"67d90f623adf47a3990e2fee1a27ec20":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2f13b6fe4604472b0b2d0effff87f69","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bd4949e6f04f44b7a2c265afc6b7d8b0","value":570}},"a49968c85f184e799b3e01713d810ca0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b90ee4aa6f364fbd8a5bfb6a04cca384","placeholder":"​","style":"IPY_MODEL_742c6c5530884112ab1cb94f22d37320","value":" 570/570 [00:00&lt;00:00, 19.6kB/s]"}},"24fb8a175a834cc28cc76414f1479ead":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37d9ed7a399448328942e2e83d4cdfe1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"470d2ba87bd54f3f850aa3c75becf258":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a2f13b6fe4604472b0b2d0effff87f69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd4949e6f04f44b7a2c265afc6b7d8b0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b90ee4aa6f364fbd8a5bfb6a04cca384":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"742c6c5530884112ab1cb94f22d37320":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f59597dbb3b4676a8b5cdb4d7d59355":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8aa684651f1b49558588b8cfbc7b9db7","IPY_MODEL_32b1d8568b874d0aa8e20615cffe6396","IPY_MODEL_e3d58ceb58b84209a47a467f6d57880f"],"layout":"IPY_MODEL_90a50e1806784f339dfd4eb50f5d0602"}},"8aa684651f1b49558588b8cfbc7b9db7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1de19254249e4e849de91446906e5ca4","placeholder":"​","style":"IPY_MODEL_88e36b00cef64e6589ea3518aae925ac","value":"Downloading pytorch_model.bin: 100%"}},"32b1d8568b874d0aa8e20615cffe6396":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a9b40e04f334b51915118c2d3e366ee","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_19aca8705872400bb56e2301c904fbc2","value":440473133}},"e3d58ceb58b84209a47a467f6d57880f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_768cca644c554686bf39fbfa7981e20e","placeholder":"​","style":"IPY_MODEL_e4bd1e3d102841d98fe44486ef1df452","value":" 440M/440M [00:02&lt;00:00, 133MB/s]"}},"90a50e1806784f339dfd4eb50f5d0602":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1de19254249e4e849de91446906e5ca4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88e36b00cef64e6589ea3518aae925ac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2a9b40e04f334b51915118c2d3e366ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19aca8705872400bb56e2301c904fbc2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"768cca644c554686bf39fbfa7981e20e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4bd1e3d102841d98fe44486ef1df452":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Import Packages"],"metadata":{"id":"ZMbntxf1SmgJ"}},{"cell_type":"code","source":["!pip install transformers\n","!python3 -m spacy download en_core_web_sm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"blxRh0pBSh2a","executionInfo":{"status":"ok","timestamp":1682975374456,"user_tz":240,"elapsed":63830,"user":{"displayName":"Liangyu Li","userId":"13176302498120902496"}},"outputId":"09111b35-4384-4da2-c850-3803293a37cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.11.0 (from transformers)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n","2023-05-01 21:09:13.539071: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-05-01 21:09:15.632875: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting en-core-web-sm==3.5.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.5.0) (3.5.2)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.22.4)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.27.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.7.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","from transformers import BertModel, BertTokenizer, AdamW\n","from tqdm import tqdm\n","import spacy\n","import csv\n","import random\n","import xml.etree.ElementTree as ET\n","#import os\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"94V5zwbgB8Hk","executionInfo":{"status":"ok","timestamp":1682975418846,"user_tz":240,"elapsed":26454,"user":{"displayName":"Liangyu Li","userId":"13176302498120902496"}},"outputId":"499c561f-1bb6-4d28-c007-75c8197741c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Data Processing"],"metadata":{"id":"dO6z-dOehyVL"}},{"cell_type":"markdown","source":["## Download the semeval2017_task7 dataset"],"metadata":{"id":"dbkiSdvYPifm"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Fsmh_cLevBI","executionInfo":{"status":"ok","timestamp":1683059407305,"user_tz":240,"elapsed":2785,"user":{"displayName":"Liangyu Li","userId":"13176302498120902496"}},"outputId":"299e7346-642b-4829-85f9-9544eb702c6d"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-05-02 20:30:04--  https://alt.qcri.org/semeval2017/task7/data/uploads/semeval2017_task7.tar.xz\n","Resolving alt.qcri.org (alt.qcri.org)... 80.76.166.231\n","Connecting to alt.qcri.org (alt.qcri.org)|80.76.166.231|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 748424 (731K) [application/x-xz]\n","Saving to: ‘semeval2017_task7.tar.xz’\n","\n","semeval2017_task7.t 100%[===================>] 730.88K   865KB/s    in 0.8s    \n","\n","2023-05-02 20:30:06 (865 KB/s) - ‘semeval2017_task7.tar.xz’ saved [748424/748424]\n","\n","\u001b[0m\u001b[01;34msample_data\u001b[0m/  \u001b[01;34msemeval2017_task7\u001b[0m/  semeval2017_task7.tar.xz\n"]}],"source":["!wget https://alt.qcri.org/semeval2017/task7/data/uploads/semeval2017_task7.tar.xz\n","!tar -xf semeval2017_task7.tar.xz\n","#!tar -xvf semeval2017_task7.tar.xz\n","#%cd semeval2017_task7/\n","#%cd ..\n","%ls"]},{"cell_type":"markdown","source":["## homographic"],"metadata":{"id":"cKmhgmUo_hf_"}},{"cell_type":"code","source":["f = 'semeval2017_task7/data/test/subtask1-homographic-test.xml'\n","\n","mytree = ET.parse(f)\n","myroot = mytree.getroot()\n","\n","puns_hom = []\n","for item in myroot.findall('./text'):\n","    dict1 = {}\n","    dict1[item.attrib['id']] = {}\n","    for child in item:\n","        idd = child.attrib['id']\n","        dict1[item.attrib['id']][idd] = child.text\n","    for pun in dict1.values():\n","        puns_hom.append([pun[x].replace(u'\\xa0', '_') for x in pun])\n","\n","print(puns_hom[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CUsbD-WD6h1q","executionInfo":{"status":"ok","timestamp":1682975428008,"user_tz":240,"elapsed":130,"user":{"displayName":"Liangyu Li","userId":"13176302498120902496"}},"outputId":"fe30fc20-32fe-4e76-eb82-0f87c9b2e2ee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['They', 'hid', 'from', 'the', 'gunman', 'in', 'a', 'sauna', 'where', 'they', 'could', 'sweat', 'it', 'out', '.']\n"]}]},{"cell_type":"code","source":["gold_hom = []\n","with open('semeval2017_task7/data/test/subtask1-homographic-test.gold', 'r') as fin:\n","    for row in fin:\n","        gold_hom.append(int(row.strip().split('\\t')[1]))\n","print(gold_hom)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BB3jjujn7WZY","executionInfo":{"status":"ok","timestamp":1682975431518,"user_tz":240,"elapsed":189,"user":{"displayName":"Liangyu Li","userId":"13176302498120902496"}},"outputId":"34bc9b2c-5c49-4eba-ee92-6f24139b5871"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1]\n"]}]},{"cell_type":"code","source":["location_hom = [-10000 for _ in range(len(puns_hom))]\n","with open('semeval2017_task7/data/test/subtask2-homographic-test.gold', 'r') as fin:\n","    for row in fin:\n","        # The default is start from 1\n","        pun_index = int(row.strip().split('\\t')[1].split('_')[2]) - 1\n","        location_hom[int(row.strip().split('\\t')[1].split('_')[1]) - 1] = pun_index\n","print(location_hom)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bQOiNbDU9W4e","executionInfo":{"status":"ok","timestamp":1682975432860,"user_tz":240,"elapsed":222,"user":{"displayName":"Liangyu Li","userId":"13176302498120902496"}},"outputId":"8db2ca43-20f6-4416-8cee-8bfe7fc75157"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[11, 8, 6, 4, 14, -10000, 13, 16, 10, 12, 8, -10000, -10000, 13, 14, 12, -10000, 7, 2, 16, 8, 14, 6, 6, 4, 14, 9, 4, 3, 7, 11, -10000, 3, 14, -10000, -10000, -10000, 8, 19, -10000, 15, -10000, 7, 11, 5, 8, 12, 9, -10000, 8, 7, 18, 7, -10000, 11, -10000, -10000, 14, -10000, 19, 9, 8, 9, -10000, -10000, -10000, 14, -10000, 10, 8, 20, 9, 8, 8, 12, 6, 13, 17, -10000, 4, 8, 5, 3, -10000, 14, 19, 12, 10, -10000, 2, 14, 9, 13, -10000, -10000, 11, 5, 14, 9, 19, -10000, -10000, 6, 16, -10000, 8, 16, 9, 9, 10, -10000, 6, 10, -10000, 10, 13, 4, -10000, 6, 11, -10000, -10000, -10000, 6, 16, 0, 15, 15, -10000, 10, -10000, 3, 11, -10000, 9, 14, 4, 14, 11, 11, 16, 16, -10000, 10, 10, -10000, 7, 14, 8, 7, 13, 20, 1, 8, -10000, 9, 7, -10000, 20, 8, 11, 7, 12, 11, 12, -10000, 5, -10000, 7, 22, -10000, 9, 7, 16, 7, -10000, 7, 14, 9, -10000, 16, -10000, 6, -10000, 11, 12, -10000, 21, 10, -10000, 10, -10000, 13, -10000, 6, 13, 12, 2, 20, -10000, 12, 11, 6, 16, -10000, 14, 7, 12, 16, -10000, -10000, -10000, -10000, 12, -10000, -10000, 11, 4, 11, 10, 18, 6, 8, 10, 7, 9, 13, 9, 2, 3, 13, -10000, 25, 5, 8, 11, 7, 2, -10000, 3, -10000, -10000, 10, -10000, 9, 8, 3, -10000, -10000, 8, 12, -10000, -10000, 15, 9, 3, -10000, 13, 12, 11, 10, 4, -10000, -10000, 9, 11, 8, 11, 6, 12, -10000, 7, 8, 13, -10000, 12, 6, 17, 10, -10000, 14, 18, 21, 13, 18, 9, 3, 16, 6, -10000, -10000, 11, 17, 10, -10000, 6, -10000, 10, -10000, 4, 13, -10000, 8, 6, 12, -10000, -10000, 34, -10000, 16, -10000, -10000, 11, -10000, 20, 13, 19, 16, 12, 6, -10000, 9, 10, 10, 11, -10000, 12, 13, 3, 7, -10000, -10000, -10000, 9, -10000, -10000, -10000, 8, 16, -10000, 9, 13, -10000, 4, 9, 11, -10000, 18, 6, 10, -10000, -10000, 4, 2, 14, 7, 6, 7, 7, 9, 6, 10, 14, 13, 17, 13, 11, 10, 10, -10000, 5, -10000, 20, 10, 10, -10000, -10000, 11, -10000, 19, 9, 7, 9, -10000, -10000, 8, 12, 10, 9, 12, 9, 4, 9, 9, 7, 17, 12, -10000, 12, 8, 12, 13, 11, 17, 11, 5, -10000, 10, 9, -10000, 7, 29, -10000, 12, 3, 2, 13, 8, -10000, -10000, 15, 19, 11, 15, -10000, 6, -10000, 9, 7, 15, 14, 19, 9, 12, -10000, -10000, 5, 13, -10000, 8, 8, 8, 9, 3, -10000, 10, 28, -10000, 16, -10000, 16, 7, -10000, 10, -10000, -10000, 11, 9, -10000, -10000, -10000, 12, 7, 9, -10000, -10000, 11, 9, -10000, 11, -10000, -10000, 22, -10000, -10000, -10000, -10000, 16, 10, -10000, 14, 8, 8, -10000, 14, 7, 20, 8, -10000, 11, 3, -10000, 6, -10000, 10, 7, 11, 3, -10000, 19, -10000, 9, 13, 16, 5, 7, -10000, 8, 4, -10000, 21, 10, 15, 9, -10000, 9, -10000, -10000, -10000, 8, -10000, 16, -10000, 8, 5, 9, 11, -10000, 7, -10000, 11, -10000, -10000, 3, 5, -10000, -10000, 6, -10000, 4, -10000, 8, 13, 7, 7, 33, 6, 20, 5, 9, -10000, 5, 3, 13, 9, 10, 8, 8, 3, -10000, -10000, -10000, 5, -10000, 9, 13, -10000, 7, 0, 7, 9, 13, 6, 10, 10, 10, -10000, 13, 12, 16, 10, 8, -10000, 16, -10000, 4, 6, 7, -10000, 10, 9, -10000, 12, 6, 13, 15, 5, 8, 11, 15, -10000, 9, -10000, 18, 5, -10000, -10000, 7, 12, -10000, -10000, 3, -10000, 17, 7, -10000, -10000, -10000, 11, 12, 5, 3, 3, 10, 8, -10000, 0, 12, 10, 7, 8, -10000, -10000, -10000, 17, 9, 10, 10, -10000, 7, -10000, 11, -10000, 8, -10000, 14, -10000, 2, 9, 13, -10000, -10000, -10000, 10, 13, 2, 12, 11, 6, 11, 16, 9, 17, 9, -10000, 8, 9, 9, -10000, 14, 5, 9, 12, 15, 15, 6, 5, 3, 7, 16, 6, -10000, -10000, 3, -10000, 10, 10, 5, 14, 4, 12, 6, 43, 9, 7, -10000, 11, 10, 16, 8, 17, -10000, 7, 10, 8, -10000, 14, 15, -10000, 23, 7, 4, 4, 13, 8, 2, 9, 9, -10000, -10000, -10000, -10000, 12, -10000, -10000, 14, 8, 8, 16, -10000, 11, 14, -10000, -10000, 2, 8, 8, 15, -10000, 9, 7, 10, -10000, 21, 13, -10000, -10000, 6, 10, -10000, 7, -10000, 16, 6, -10000, 15, -10000, 10, 6, 3, -10000, 6, 8, 13, 10, 12, 12, 13, 12, 9, 15, -10000, -10000, 3, 22, -10000, -10000, 11, 11, 18, -10000, -10000, 18, -10000, 22, -10000, 32, 10, 3, 12, 17, 14, 6, -10000, -10000, 9, -10000, -10000, 10, 14, -10000, 4, -10000, 9, 8, 2, 9, 7, -10000, 11, 16, 7, -10000, 11, 5, -10000, 10, -10000, 14, 10, 9, -10000, -10000, -10000, 12, -10000, -10000, 17, 16, -10000, -10000, -10000, 10, 12, 18, 6, -10000, 9, -10000, -10000, 15, -10000, 14, 3, 8, -10000, 25, 13, -10000, -10000, 7, 11, 10, 9, 4, 16, 14, 5, -10000, 7, 16, 20, 4, 24, -10000, 25, -10000, 15, -10000, 14, 9, 8, 9, -10000, -10000, 8, 8, 9, -10000, -10000, 10, 3, -10000, 3, 1, 11, -10000, 12, 20, 4, 8, -10000, -10000, -10000, 11, -10000, 14, 5, -10000, 7, 9, 3, 6, -10000, -10000, 3, 12, 18, -10000, 7, 14, 8, 8, 6, 15, 7, 14, 16, -10000, 10, -10000, 17, 5, 9, 9, 8, -10000, 16, 12, -10000, -10000, -10000, -10000, 9, -10000, -10000, 21, 7, 5, 21, 27, 9, 8, -10000, 13, 11, -10000, 3, 16, -10000, -10000, -10000, -10000, 12, 9, 7, 2, 14, 14, 12, 17, 15, -10000, 12, -10000, 15, -10000, 0, 13, 7, 5, 7, 6, 7, -10000, 12, 10, 3, 17, -10000, 12, -10000, 9, 20, 10, -10000, 9, 13, 13, 10, 25, 20, 18, 10, 16, 15, -10000, 18, 16, -10000, -10000, 10, -10000, 11, -10000, 10, 14, 7, 17, 8, -10000, 9, 4, 16, 12, 17, 14, 6, 11, 6, -10000, 10, 2, 11, 7, -10000, 15, 19, -10000, 7, 10, 10, -10000, 15, 10, 12, 6, -10000, 8, 7, -10000, 6, 9, 11, 11, -10000, 12, 4, 6, 7, 9, 17, 1, 3, 5, 42, 8, 8, -10000, 14, 12, 8, 12, -10000, 13, 14, 15, 21, 12, -10000, 17, 16, 16, 11, -10000, -10000, 7, 7, 12, 3, 13, 11, 10, 11, 9, 6, -10000, 3, -10000, 17, 0, 11, 11, -10000, -10000, -10000, -10000, -10000, -10000, 12, 20, 12, 7, -10000, 5, -10000, 21, -10000, 3, 8, 2, 7, 10, 4, -10000, 15, 6, -10000, 43, 27, -10000, 13, 17, 9, -10000, 5, 10, 6, -10000, 13, -10000, 11, 9, 12, 11, 15, -10000, -10000, 13, 24, 9, -10000, 1, 25, -10000, -10000, 9, 17, -10000, -10000, 19, -10000, 9, 4, 9, 7, -10000, 8, -10000, 15, 12, 7, 7, 23, 8, 3, -10000, 13, -10000, -10000, 20, 2, 7, 8, 12, -10000, 14, 9, 6, -10000, 18, 17, 19, 17, 7, 13, 3, -10000, -10000, 10, 14, 8, 3, 15, 12, 15, 18, 9, -10000, 6, 5, -10000, 9, -10000, -10000, 3, -10000, -10000, 17, -10000, 4, 3, 17, 8, 13, -10000, 8, -10000, 12, -10000, -10000, 15, -10000, 16, 20, -10000, 5, -10000, 11, -10000, 15, 15, -10000, 11, -10000, 13, 18, 4, 11, -10000, 3, -10000, 3, 3, 3, 6, 7, 12, 7, -10000, 17, -10000, 9, 19, -10000, -10000, 10, -10000, 17, 26, 13, 10, 22, 6, 14, -10000, 15, 9, 10, 8, 10, 5, -10000, 11, 19, 6, 5, 15, 17, -10000, 6, 8, 14, 5, -10000, 8, 15, -10000, -10000, 7, 5, 14, -10000, 12, 7, 11, -10000, 2, -10000, 9, 12, 13, -10000, 10, 7, -10000, 3, 7, 24, 7, 9, 5, -10000, 13, 6, -10000, 14, -10000, -10000, 6, 12, -10000, 8, 13, 7, 15, 17, 7, 7, -10000, 16, 17, -10000, 9, -10000, 8, -10000, 11, 16, 6, 15, 11, 11, 9, 15, 3, -10000, 12, 11, 18, 9, 6, -10000, 18, 3, 14, 8, 8, 25, 10, -10000, -10000, 9, 11, 9, 11, 15, 12, 1, -10000, -10000, 9, 8, 13, 3, -10000, 11, 3, 7, -10000, 13, 11, 14, 11, 7, -10000, 19, -10000, 7, -10000, 6, 9, 8, 7, 11, 9, 5, -10000, -10000, 18, 12, -10000, 9, 14, -10000, -10000, 3, 12, -10000, 8, -10000, 18, -10000, 15, -10000, 19, 9, 9, 9, 8, 12, -10000, 14, 19, 9, 7, 2, 7, 25, -10000, 9, 9, 9, 3, 16, 8, 14, 9, 10, 9, 8, 13, -10000, 10, -10000, -10000, 5, -10000, 19, 8, 15, 14, 2, -10000, -10000, 5, -10000, 0, 3, 13, -10000, 17, 16, -10000, 16, 22, -10000, -10000, 3, 4, 10, -10000, 12, -10000, -10000, 13, 14, -10000, 21, -10000, 9, 0, 11, -10000, 14, 4, 0, 17, -10000, -10000, 10, 13, -10000, -10000, 22, 15, 11, -10000, 8, -10000, 11, 6, 3, 9, 21, 8, 14, 14, 6, 6, 2, 9, 5, 4, 3, 13, 13, 17, 9, 6, 8, -10000, 13, -10000, -10000, 8, 17, -10000, 7, -10000, 12, 13, -10000, 16, 9, -10000, 8, 5, 9, 14, 11, 8, 13, 8, 16, 9, 9, 15, 13, -10000, 3, -10000, 10, 3, 10, 6, 5, 8, 9, 6, 15, 9, 11, 13, 8, -10000, 12, -10000, 8, 10, -10000, -10000, 5, 14, -10000, -10000, -10000, 9, 15, -10000, -10000, -10000, -10000, 5, 12, 28, 8, 15, 12, 19, 6, 10, 3, 19, -10000, 9, -10000, -10000, -10000, -10000, -10000, 19, -10000, 3, 14, -10000, 9, 10, 15, 10, -10000, -10000, -10000, 11, 6, 6, 14, 12, -10000, 10, 13, 6, -10000, 8, 13, 3, 9, 9, 7, -10000, 9, 14, -10000, -10000, 10, 10, 14, 11, -10000, -10000, -10000, 5, -10000, -10000, 10, 6, 9, 10, -10000, 5, 21, 7, 12, 3, 5, 14, 8, 9, 11, 9, 11, -10000, 7, -10000, 15, 4, -10000, -10000, -10000, 9, 9, -10000, -10000, -10000, 9, 11, 12, 0, -10000, 8, -10000, 13, -10000, -10000, 9, 6, 12, -10000, 6, 3, 14, 10, -10000, 11, 9, 16, 25, 16, 3, 15, 6, 4, 12, 14, -10000, -10000, 12, 2, 4, -10000, 6, 13, 12, 7, 6, -10000, 5, -10000, 12, 14, -10000, -10000, -10000, -10000, -10000, 12, 10, 10, 9, 15, -10000, 11, -10000, 11, 3, 6, 3, -10000, 10, -10000, -10000, 19, -10000, 11, -10000, -10000, 9, 18, 14, 10, 19, -10000, 13, 11, 3, 13, 12, 10, 12, 7, 4, 6, 15, 16, -10000, 8, 10, 7, -10000, 9, 9, -10000, 12, -10000, 9, -10000, -10000, 12, -10000, 8, 4, 15, 8, -10000, 4, 12, 8, -10000, -10000, 9, 6, 23, -10000, 8, 16, 8, 14, 4, 7, -10000, 6, -10000, 14, 13, 14, 11, 9, 8, 5, -10000, -10000, 10, 11, 11, 16, -10000, -10000, -10000, 4, 12, 9, 16, 8, 10, 1, 11, -10000, 11, -10000, 6, 7, 8, 9, 4, 7, 10, 14, 16, -10000, 15, 9, -10000, 11, 8, -10000, 12, -10000, 12, 6, 17, 8, 8, 12, 2, 3, 6, 21, 6, 17, 10, 12, 19, 7, -10000, -10000, 8, -10000, 8, -10000, 10, 12, 8, 23, -10000, 12, 7, 13, 15, 14, 9, -10000, -10000, 12, 18, 12, 12, 9, 12, -10000, -10000, 8, 7, -10000, 16, -10000, -10000, -10000, -10000, -10000, -10000, -10000, -10000, 8, -10000, 13, 7, 13, -10000, -10000, -10000, -10000, 14, 12, -10000, 5, -10000, 10, 16, -10000, 10, 23, 8, 12, 18, 11, 7, 10, 2, 11, 2, -10000, 13, 8, 15, -10000, 11, -10000, 4, -10000, 13, 8, 8, 3, 10, 9, 18, 14, 10, -10000, -10000, 15, 16, 11, 21, 15, 22, 10, 8, -10000, 5, -10000, 5, 9, 7, 19, 3, -10000, 13, 9, 4, 8, 12, -10000, 3, 10, 13, 9, 14, 7, 7, -10000, 11, 13, -10000, 4, 9, 8, 13, 13, 2, 15, 4, -10000, 10, 6, 5, -10000, -10000, 6, -10000, 10, 4, -10000, 9, 6, 3, -10000, 7, 16, 10, 14, 4, -10000, 18, 7, 9, 10, 15, 12, -10000, 2, -10000, 17, 8, 10, -10000, 2, 5, 14, 8, -10000, 13, 21, 11, -10000, 13, 5, 1, 20, 9, 1, 3, -10000, 6, 3, -10000, -10000, 15, -10000, 12, 11, 7, 0, -10000, 8, 3, 18, 10, -10000, 16, 16, 7, 7, 10, 9, 12, 14, 11, 11, -10000, 12, 8, 20, -10000, -10000, 11, 13, 7, 7, 10, 13, -10000, 10, 5, 13, -10000, 9, 17, 14, -10000, 3, 2, 8, 14, -10000, 17, 7, -10000, 8, 11, 3, 4, 13, 8, -10000, 7, 10, 8, -10000, 13, 14, -10000, 8, 16, -10000, 18, 6, 15, 6, 17, 18, 6, -10000, 12, 12, 12, 9, -10000, 13, -10000, -10000, 10, 9, 18, 11, 18, -10000, 12, 10, 16, 9, 6, 0, 7, -10000, -10000, 3, 11, -10000, 0, -10000, 10, 12, -10000, 9, -10000, 5, 10, 18, 12, 9, -10000, 13, 16, 10, 8, -10000, 7, 13, 10, -10000, -10000, 11, -10000, 10, 9, 3, 9, 9, 11, 17, -10000, 9, 3, 12, 15, 3, -10000, -10000, -10000, 3, 10, -10000, -10000, -10000, -10000, 3, -10000, -10000, 8, -10000, 10, -10000, 7, -10000, -10000, 3, 9, 2, 11, -10000, 21, 3, 3, -10000, 5, 14, -10000, -10000, 2, -10000, 3, -10000, 10, -10000, -10000, 8, 18, 4, -10000, 11, -10000, 5, -10000, 12, 2, 10, 8, 8, 19, 11, 7, -10000, 8, 9, -10000, -10000, 7, 12, 7]\n"]}]},{"cell_type":"code","source":["assert len(puns_hom) == len(gold_hom)\n","assert len(gold_hom) == len(location_hom)"],"metadata":{"id":"hDWfG2mr_Exj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## heterographic"],"metadata":{"id":"rFRjHj_b_2YK"}},{"cell_type":"code","source":["f = 'semeval2017_task7/data/test/subtask1-heterographic-test.xml'\n","\n","mytree = ET.parse(f)\n","myroot = mytree.getroot()\n","\n","puns_het = []\n","for item in myroot.findall('./text'):\n","    dict1 = {}\n","    dict1[item.attrib['id']] = {}\n","    for child in item:\n","        idd = child.attrib['id']\n","        dict1[item.attrib['id']][idd] = child.text\n","    for pun in dict1.values():\n","        puns_het.append([pun[x].replace(u'\\xa0', '_') for x in pun])\n","\n","print(puns_het[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lD2D5e_x_xUK","executionInfo":{"status":"ok","timestamp":1682975436044,"user_tz":240,"elapsed":223,"user":{"displayName":"Liangyu Li","userId":"13176302498120902496"}},"outputId":"4ee17ded-eb35-475d-e544-284e09390f01"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[\"'\", \"'\", 'I', \"'\", 'm', 'halfway', 'up', 'a', 'mountain', ',', \"'\", \"'\", 'Tom', 'alleged', '.']\n"]}]},{"cell_type":"code","source":["gold_het = []\n","with open('semeval2017_task7/data/test/subtask1-heterographic-test.gold', 'r') as fin:\n","    for row in fin:\n","        gold_het.append(int(row.strip().split('\\t')[1]))\n","print(gold_het)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9DVjLUSz_-bs","executionInfo":{"status":"ok","timestamp":1682975437798,"user_tz":240,"elapsed":233,"user":{"displayName":"Liangyu Li","userId":"13176302498120902496"}},"outputId":"dcdd6f07-3496-4562-a57b-61cbfbf0f415"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"]}]},{"cell_type":"code","source":["location_het = [-10000 for _ in range(len(puns_het))]\n","with open('semeval2017_task7/data/test/subtask2-heterographic-test.gold', 'r') as fin:\n","    for row in fin:\n","        # The default is start from 1\n","        pun_index = int(row.strip().split('\\t')[1].split('_')[2]) - 1\n","        location_het[int(row.strip().split('\\t')[1].split('_')[1]) - 1] = pun_index\n","print(location_het)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ryJLOM-U_-Uc","executionInfo":{"status":"ok","timestamp":1682975439533,"user_tz":240,"elapsed":159,"user":{"displayName":"Liangyu Li","userId":"13176302498120902496"}},"outputId":"d652583a-f45d-44a1-ef2f-ac6fdc319e1b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[13, 12, -10000, 10, 4, -10000, 5, 3, 5, 7, 12, 11, 23, -10000, 2, 10, 6, -10000, 15, 15, -10000, 16, 12, 5, 6, 11, -10000, 9, -10000, -10000, 13, -10000, 23, 15, 13, 16, -10000, 12, 14, 5, -10000, 10, 9, 14, 7, 9, 7, -10000, 7, 3, 10, -10000, -10000, 28, 10, 6, -10000, 13, 12, 15, -10000, 12, -10000, 15, 17, 7, 6, -10000, 13, 26, 13, 3, 12, 12, 16, 11, 4, 6, -10000, 10, -10000, 10, 10, -10000, -10000, 9, 11, -10000, 10, 5, -10000, 7, -10000, 6, 18, 8, 3, -10000, 11, 6, 15, 5, -10000, 4, 3, 14, 7, 13, -10000, -10000, 7, 10, 12, -10000, -10000, 6, 30, -10000, 6, -10000, 14, 6, 14, 11, 6, 39, -10000, -10000, 11, -10000, 16, -10000, 8, 15, -10000, 24, 23, 17, -10000, 13, 5, 11, 14, 3, 13, -10000, -10000, 4, 6, 8, -10000, -10000, 12, 14, -10000, 1, 3, 6, 12, -10000, -10000, 4, -10000, -10000, 17, 25, -10000, 9, -10000, -10000, -10000, 19, -10000, 6, -10000, -10000, 6, -10000, 16, -10000, 22, -10000, 13, 8, 12, 19, 17, 16, 9, -10000, 14, -10000, 14, 5, 10, 12, 5, -10000, -10000, 16, 6, 6, 8, 11, -10000, 11, -10000, 8, 16, -10000, -10000, -10000, 8, -10000, 3, 9, 9, 8, 10, -10000, 13, 21, 6, 8, -10000, -10000, 10, 10, 7, -10000, 10, -10000, -10000, 8, 10, 13, -10000, -10000, 6, 4, -10000, 5, -10000, 11, -10000, 10, 19, 10, 12, 8, 19, 12, 21, 12, -10000, -10000, 11, 8, 14, 8, 25, -10000, 9, 8, 9, -10000, 11, 14, -10000, 14, -10000, 3, -10000, -10000, -10000, 5, 21, 11, -10000, -10000, -10000, 5, 18, 13, 10, -10000, 3, 7, 11, -10000, 14, 6, 0, 21, -10000, 7, -10000, 16, 17, 7, 6, 19, 7, -10000, 7, 15, -10000, 30, 12, 16, 13, 7, 16, 2, 8, 10, 16, 11, -10000, 5, -10000, 11, 11, 5, 6, 10, -10000, 2, 7, -10000, 9, 17, 10, 10, 24, 13, 11, 8, -10000, -10000, 12, 9, 3, 14, 16, 4, 7, 17, -10000, 10, 37, -10000, 13, 6, -10000, 13, 17, 9, -10000, 9, 10, 12, 7, 10, 15, 24, -10000, -10000, 7, 32, -10000, -10000, 11, 8, 19, -10000, 18, -10000, 8, 15, 11, 20, -10000, 9, -10000, 7, 15, 13, 17, -10000, 16, -10000, 7, 14, -10000, 11, -10000, 7, 3, 16, -10000, -10000, -10000, -10000, 7, 18, -10000, 9, 10, 15, 14, 18, -10000, -10000, 12, 3, 17, 18, 13, 14, 14, -10000, -10000, 11, -10000, 14, 28, 7, 11, 4, 10, -10000, -10000, 2, 31, 11, -10000, -10000, -10000, 12, -10000, 11, -10000, 5, 10, 27, -10000, -10000, 6, 10, 14, -10000, 9, 15, -10000, -10000, 8, 11, 15, 0, 9, 13, 3, 9, -10000, 7, 4, 18, 12, 7, 15, 3, 8, -10000, -10000, -10000, 2, 13, 14, 16, 31, 5, 1, -10000, 10, 14, 7, 14, 20, -10000, 4, 7, 12, 6, -10000, 4, 4, 16, 8, -10000, 15, 8, 13, 9, 6, 18, -10000, 10, 8, 7, -10000, -10000, 27, 8, -10000, 10, 2, 7, 6, 19, -10000, 4, 16, 16, 26, -10000, 30, 10, -10000, 4, -10000, -10000, -10000, 10, 17, -10000, 17, 6, 19, 13, 3, 13, 14, 6, 14, -10000, -10000, 7, 6, 6, 8, 10, 9, 9, 6, 17, -10000, 11, 12, 7, 6, 7, -10000, 22, -10000, 5, 11, -10000, -10000, -10000, 8, -10000, 10, 15, 6, -10000, -10000, 9, 7, 24, -10000, 14, 1, 16, 7, 11, 7, 4, 39, -10000, 9, 12, 20, -10000, 11, -10000, 31, -10000, -10000, 3, 8, 12, -10000, -10000, 13, 18, 16, 9, 13, 63, 6, 11, -10000, -10000, -10000, -10000, 6, 10, 7, -10000, 16, 7, -10000, 16, 1, -10000, 17, 18, 6, 9, 11, 22, 8, 3, 11, 7, -10000, 6, 18, 7, -10000, -10000, 20, 22, 10, 7, 11, -10000, 7, -10000, 18, 17, 16, 3, 13, 13, 15, -10000, -10000, -10000, 9, 10, 9, -10000, 15, 10, 13, 10, 7, 4, 3, 10, -10000, 14, 13, 13, 5, 21, -10000, -10000, 15, -10000, 10, 19, 15, 7, -10000, -10000, 10, 3, 18, 5, 11, 3, -10000, -10000, 20, 7, 8, 18, 8, -10000, 14, 6, 3, 8, -10000, 14, 9, 19, 19, -10000, -10000, 10, -10000, 10, 15, 17, 7, 10, 15, 1, 9, 7, 11, -10000, 12, -10000, -10000, 10, 17, 15, 6, -10000, 8, 10, 9, -10000, -10000, 9, -10000, 16, 9, -10000, -10000, 12, -10000, -10000, 29, 6, 10, 14, 9, 7, 20, 12, 15, 14, 11, 9, 14, 1, 2, 10, 1, -10000, -10000, 16, 7, 12, 10, -10000, 10, -10000, 7, 11, 22, -10000, 16, -10000, 12, 17, 15, 17, 12, 6, -10000, 9, -10000, -10000, 8, 5, 9, 10, 20, -10000, 13, 16, 14, -10000, -10000, 11, 12, 10, 10, 14, 10, 19, -10000, 10, -10000, -10000, 8, 18, 16, -10000, -10000, 8, -10000, 8, 24, 10, -10000, 9, 11, 9, 30, 6, 18, 9, -10000, 0, -10000, 19, -10000, 11, 13, -10000, -10000, 18, -10000, 2, 23, 15, -10000, -10000, 18, 11, 12, -10000, 7, 3, -10000, 20, 19, -10000, 15, -10000, 11, -10000, 8, -10000, 4, 12, -10000, 10, 12, -10000, 19, 13, 18, 17, -10000, 8, 4, 3, 11, -10000, -10000, 17, 4, 9, 18, -10000, 11, 7, 8, 9, 7, 8, 34, 11, 12, -10000, 13, -10000, 3, 17, -10000, 18, 16, 4, 18, 3, 20, -10000, 7, 7, 8, 3, 13, 3, 10, 6, 12, -10000, -10000, -10000, -10000, 6, 8, 5, 12, 5, -10000, 13, -10000, 11, 4, 6, -10000, -10000, 4, 7, 13, -10000, 7, -10000, 14, 9, -10000, 15, 15, 29, 6, -10000, -10000, 8, 21, 7, 0, 16, 8, 8, 19, 3, -10000, 27, -10000, -10000, -10000, -10000, -10000, 6, -10000, -10000, -10000, -10000, 8, -10000, 19, -10000, 15, 18, -10000, -10000, 9, 16, -10000, 10, 8, 14, 8, 11, 9, 13, 14, -10000, 10, 5, 11, 9, 23, -10000, 3, -10000, 9, 10, -10000, -10000, 16, 13, 0, 6, 18, 12, 12, 13, -10000, 12, 16, 21, 10, 15, -10000, 14, 12, 73, 11, 11, 13, 12, -10000, 8, -10000, 9, 9, 13, 8, 9, 13, 11, 16, 6, 10, 21, 10, 8, 18, -10000, -10000, 15, 44, -10000, 16, 10, 3, 8, 5, 9, 15, 11, 14, 16, 19, 16, 8, -10000, -10000, -10000, 12, 8, 13, -10000, 32, 21, 18, -10000, -10000, 15, 9, -10000, 16, 36, 2, 7, 15, 8, 8, 14, -10000, 13, -10000, 14, 10, 8, -10000, 25, 13, 8, 13, -10000, -10000, 7, 9, 15, 3, 12, 12, -10000, 10, -10000, 35, 22, 11, 11, 3, -10000, 4, 17, -10000, 7, 13, 15, 9, 4, 9, 12, 3, -10000, -10000, 12, 11, -10000, -10000, 7, 15, 9, 4, 10, -10000, 7, 18, 14, -10000, 9, 7, 9, -10000, 14, 21, 13, 12, 18, -10000, -10000, 3, 13, -10000, 6, -10000, 20, -10000, -10000, 8, 8, 12, -10000, 10, 8, -10000, -10000, -10000, 3, -10000, -10000, 9, 12, -10000, -10000, 8, -10000, 8, 9, 34, 10, 19, -10000, -10000, 13, 7, -10000, 15, 10, 8, 12, -10000, -10000, -10000, 9, -10000, -10000, 14, 14, 16, -10000, 8, -10000, 8, 14, 6, 8, 4, 13, 17, 12, 25, -10000, 13, -10000, -10000, 1, 13, 14, 8, 9, 8, 7, 16, -10000, 10, 2, -10000, -10000, 8, 9, 15, 6, 17, -10000, -10000, 15, 3, -10000, -10000, -10000, 25, 1, 8, -10000, 7, 11, 4, 14, -10000, -10000, 7, 15, 10, 11, 11, -10000, -10000, 30, 16, 12, -10000, -10000, 16, 11, 16, 4, -10000, 2, 12, 9, -10000, 4, 7, -10000, 10, 7, 7, -10000, 9, 14, -10000, 11, -10000, 3, -10000, 10, 15, 11, 8, 9, 8, -10000, 15, 11, 12, 14, -10000, -10000, 11, 14, 17, 5, 11, 11, 11, 15, 19, 17, 7, -10000, -10000, 7, -10000, 11, 3, 7, -10000, 22, 13, 3, 23, -10000, 9, -10000, -10000, 10, -10000, -10000, -10000, -10000, 14, 13, 7, 1, 15, 13, 5, -10000, 5, 8, 11, -10000, 8, 7, -10000, 15, -10000, -10000, 10, 9, 7, 8, 7, -10000, 9, -10000, 7, 4, -10000, 9, -10000, -10000, 5, 0, 12, 19, 8, 10, 13, -10000, 13, 12, 10, 12, 5, 7, -10000, -10000, -10000, -10000, -10000, 16, 10, 6, 14, 11, -10000, 17, 11, 4, 15, 7, 11, 17, 4, 10, 13, 7, 10, 7, 3, 13, 11, -10000, 8, 7, 9, -10000, 3, 19, 7, -10000, -10000, -10000, -10000, 7, 11, 17, -10000, 10, 10, 75, 6, 10, 17, 16, 22, -10000, 12, -10000, 14, 17, 11, -10000, 15, 15, 10, 12, 6, 11, 9, 4, -10000, -10000, 18, 13, 7, 8, -10000, 6, 12, -10000, 10, 13, -10000, 3, 7, 7, 3, 7, 26, 6, 7, -10000, 17, -10000, 9, 3, 14, 15, 9, 9, 12, 13, 5, 8, 5, 8, 6, 6, 10, 4, 9, 3, 11, 33, 15, 12, -10000, 34, 10, 25, 55, 14, 12, 1, -10000, 10, 29, -10000, 15, 5, 9, 9, 11, 14, 11, 29, 4, 8, 3, 12, 7, 12, 9, 14, -10000, 16, 21, -10000, -10000, 11, 7, -10000, -10000, -10000, -10000, 1, 2, 12, 15, 14, 9, 4, 18, 11, -10000, -10000, -10000, -10000, 11, 13, 10, -10000, 5, 13, -10000, 8, 5, 36, 6, -10000, 15, -10000, -10000, -10000, 9, 7, 7, 6, 21, 25, -10000, 8, 6, -10000, 10, -10000, -10000, 8, -10000, -10000, 13, -10000, 13, 27, -10000, -10000, 10, 5, -10000, 5, 14, 6, 2, 14, 11, -10000, -10000, 6, 8, 11, 8, 14, -10000, -10000, -10000, 20, 11, -10000, 28, 6, 19, 15, -10000, 13, -10000, 18, 8, 16, -10000, 5, -10000, 9, 9, 14, 7, 15, 9, 14, 8, -10000, 32, -10000, -10000, 11, -10000, 7, 15, 5, 13, -10000, 11, 11, 18, -10000, 4, 19, 33, 13, 7, 7, 10, 11, -10000, 13, 9, 8, 6, -10000, 11, 15, 10, -10000, 9, -10000, 12, 11, -10000, 13, 10, 23, 6, 0, 9, 13, 17, -10000, 14, 15, -10000, 14, -10000, -10000, 8, -10000, -10000, 14, -10000, 3, 3, 27, 18, -10000, -10000, -10000, 5, -10000, 21, 6, 20, -10000, -10000, 7, 8, -10000, 6, 7, -10000, -10000, 22, 8, 9, 6, -10000, 20, 14, 12, -10000, -10000, 11, 17, 6, 7, 13, -10000, -10000, 5, 6, -10000, 11, 14, 10, -10000, 12, 7, 11, 18, 8, 13, -10000, 4, 5, 11, 8, 7, -10000, 13, 8, 15, 16, 10, -10000, 13, -10000, 6, 3, 10, 3, 3, -10000, -10000, 8, 9, 5, 11, -10000, 14, 12, 7, -10000, -10000, -10000, 3, 4, 7, 6, -10000, 7, 12, 17, 6, 7, -10000, 11, 0, 16, 15, 10, 12, 9, 14, 5, 13]\n"]}]},{"cell_type":"code","source":["assert len(puns_het) == len(gold_het)\n","assert len(gold_het) == len(location_het)"],"metadata":{"id":"B6-7nqa6_-L0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Puns of the Day"],"metadata":{"id":"_BNAAP3vBpFh"}},{"cell_type":"code","source":["texts_PTD = []\n","labels_PTD = []\n","nlp = spacy.load('en_core_web_sm')\n","\n","# text = 'My first birthday was great. My 2. was even better.'\n","# sentences = [str(tok) for sent in nlp(text).sents for tok in sent]\n","\n","# opening the CSV file\n","with open(\"/content/drive/My Drive/puns_pos_neg_data.csv\", mode ='r') as file:\n","\n","    # reading the CSV file\n","    csvFile = csv.reader(file)\n","    \n","    # displaying the contents of the CSV file\n","    for line in csvFile:\n","        #print(line)\n","        labels_PTD.append(0 if line[0] == \"-1\" else 1)\n","        texts_PTD.append([str(tok) for sent in nlp(line[1]).sents for tok in sent])\n","\n","del texts_PTD[0] # delete the head\n","del labels_PTD[0] # delete the head\n","assert len(texts_PTD) == len(labels_PTD)"],"metadata":{"id":"ml4Wp0C_BsvA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Get Total Dataset"],"metadata":{"id":"GXjWFHRnVDHF"}},{"cell_type":"code","source":["num_pos_task_7 = sum(gold_hom + gold_het)\n","print(num_pos_task_7)\n","num_neg_task_7 = len(gold_hom + gold_het) - num_pos_task_7\n","print(num_neg_task_7)\n","num_delta = num_pos_task_7 - num_neg_task_7\n","print(num_delta)\n","\n","# PTD: from iindex=2423 is neg\n","total_puns = puns_hom + puns_het + texts_PTD[-num_delta:]\n","total_gold = gold_hom + gold_het + labels_PTD[-num_delta:]\n","total_location = location_hom + location_het + [-10000 for _ in range(num_delta)]\n","# -10000 means has no pun in the sentence\n","assert len(total_puns) == len(total_gold)\n","assert len(total_gold) == len(total_location)\n","assert sum(total_gold) * 2 == len(total_puns)\n","print()\n","\n","print(len(total_puns))\n","print(sum(total_gold))\n","print(sum([1 for i in total_location if i == -10000]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RginZl7TS4yD","executionInfo":{"status":"ok","timestamp":1682975495303,"user_tz":240,"elapsed":181,"user":{"displayName":"Liangyu Li","userId":"13176302498120902496"}},"outputId":"1a33960b-dff8-4a85-e705-b6be43a054b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2878\n","1152\n","1726\n","\n","5756\n","2878\n","2878\n"]}]},{"cell_type":"code","source":["# Set up the device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Model parameters\n","bert_model_name = 'bert-base-uncased'\n","\n","# Load the tokenizer\n","tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n","\n","max_length = 80\n","batch_size = 32"],"metadata":{"id":"5GLGmt8qdCul","colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["611aaf35c5cb422da9faf1905de9423f","862318de4c4a4958868d213650e92708","d3a78e4b701148b0aa8215a9db3c6989","d8a074de98cd44dd8a4bf17a127119c1","ee536f94084a495ab1763ed6648210d8","86fedfe45fa24c33b03fe21507cd8595","f7ae8291d29b460eaae3a9cc803b2f5e","fd6708d7d93e49b0924ac65cccf5429d","b291948b79a541bda4777a6052274222","859375b65f98404c8d2135101a8724e0","9699a5c54eef405b8845b2211ce728db","6b9c98c40ce048638c8072aa2b1527fc","fef4e54403f54189b2d640669f93a098","5251319c95924f239ee8374102f92999","0d984ac7a0244adb927f0b0a15397ccf","cdb004b884fa4895a682a40a6bb5f036","7539f9550a584d8593b3f049df67738f","906962d5394a4f768addfc1d06169307","fd325f439cc84ea29d95463d5e683d85","f3b1dfc6abce4de5b037d05bb8ab4eb6","e22524ac2e874a68aef0968ebebd41c8","d3691e8da91d48b58fc3176aaa2f466e","c4b94eb66bf347e1a85703dbe1f03502","938fbc2b81e74ac6a5c4246b5587a5f2","67d90f623adf47a3990e2fee1a27ec20","a49968c85f184e799b3e01713d810ca0","24fb8a175a834cc28cc76414f1479ead","37d9ed7a399448328942e2e83d4cdfe1","470d2ba87bd54f3f850aa3c75becf258","a2f13b6fe4604472b0b2d0effff87f69","bd4949e6f04f44b7a2c265afc6b7d8b0","b90ee4aa6f364fbd8a5bfb6a04cca384","742c6c5530884112ab1cb94f22d37320"]},"executionInfo":{"status":"ok","timestamp":1682975498422,"user_tz":240,"elapsed":489,"user":{"displayName":"Liangyu Li","userId":"13176302498120902496"}},"outputId":"8a0ba2b3-4e07-4263-e405-7845c88f5b49"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"611aaf35c5cb422da9faf1905de9423f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b9c98c40ce048638c8072aa2b1527fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4b94eb66bf347e1a85703dbe1f03502"}},"metadata":{}}]},{"cell_type":"code","source":["total_corresponding_location = []\n","# the corresponding location,\n","# means the corresponding location of the token ID after tokenize (index start with 0)\n","\n","for pun, gold, location in zip(total_puns, total_gold, total_location):\n","\n","    if gold == 1:\n","        current_index = 0\n","        start = False\n","        for word_idx, x in enumerate(pun):\n","            subwords = tokenizer.tokenize((' ' if start else '') + x)\n","            start = True\n","            for i in range(1, len(subwords)):\n","                subwords[i] = subwords[i][2:] # delete the '##'\n","\n","            subwords_len = np.zeros((len(subwords),), dtype=float)\n","            for count_index, each_token in enumerate(subwords):\n","                subwords_len[count_index] = len(each_token)\n","            longest_index = np.argmax(subwords_len, axis=0)\n","\n","            if 1 + current_index + longest_index >= max_length - 1:\n","                # Cannot longer than max_length\n","                # because the input_ids has a start ID and end ID\n","                # which needs to +1 and -1 to match the index\n","                print(\"The corresponding location index is out of range!\")\n","\n","            if word_idx == location:\n","                total_corresponding_location.append(current_index + longest_index)\n","                break\n","\n","            current_index += len(subwords)\n","            \n","        else:\n","            # Not break\n","            print(\"Something Wrong!\")\n","            \n","    else:\n","        # gold == 0\n","        total_corresponding_location.append(-10000)\n","\n","assert len(total_corresponding_location) == len(total_puns)"],"metadata":{"id":"Y3jn1q2QblSb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = []\n","# input_ids, attention_mask, label, location_index, corresponding_location\n","\n","for pun, gold, location, corresponding_location in tqdm(zip(total_puns, total_gold, total_location, total_corresponding_location)):\n","    sentence = ' '.join(pun)\n","    tokenized = tokenizer(sentence, return_tensors=\"pt\", max_length=max_length, truncation=True, padding=\"max_length\")\n","    dataset.append(\n","        {\n","            'input_ids': tokenized[\"input_ids\"][0],\n","            'attention_mask': tokenized[\"attention_mask\"][0],\n","            'label': torch.tensor(gold, dtype=torch.long),\n","            'location': torch.tensor(location, dtype=torch.long),\n","            'corresponding_location': torch.tensor(corresponding_location, dtype=torch.long)\n","         }\n","    )\n","\n","random.shuffle(dataset)\n","\n","\n","# Split the dataset into training and validation sets\n","train_dataset, val_dataset = torch.utils.data.random_split(\n","    dataset, [len(total_puns)-int(0.2*len(total_puns)), int(0.2*len(total_puns))])\n","\n","# Create DataLoaders for each set with a batch size\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8HGhZm-BnR4C","executionInfo":{"status":"ok","timestamp":1682975520617,"user_tz":240,"elapsed":3319,"user":{"displayName":"Liangyu Li","userId":"13176302498120902496"}},"outputId":"a56d9a54-4b0b-47fb-ee92-9c67d11f9396"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["5756it [00:03, 1797.94it/s]\n"]}]},{"cell_type":"markdown","source":["## Setup the Model"],"metadata":{"id":"xFdZ3Mv9s-RX"}},{"cell_type":"code","source":["# Define the BERT-BiLSTM model\n","class BertBiLSTM(nn.Module):\n","    def __init__(self, bert_model_name, num_classes, hidden_dim, num_layers, bidirectional, dropout):\n","        super(BertBiLSTM, self).__init__()\n","        self.bert = BertModel.from_pretrained(bert_model_name)\n","        # Set the BERT layer as untrainable\n","        '''\n","        for param in self.bert.parameters():\n","            param.requires_grad = False\n","        '''\n","        self.lstm = nn.LSTM(\n","            input_size=self.bert.config.hidden_size,\n","            hidden_size=hidden_dim,\n","            num_layers=num_layers,\n","            bidirectional=bidirectional,\n","            batch_first=True,\n","            dropout=dropout if num_layers > 1 else 0\n","        )\n","        self.dropout = nn.Dropout(dropout)\n","        #self.classifier = nn.Linear(hidden_dim * (2 if bidirectional else 1), num_classes)\n","        self.classifier = nn.Linear(hidden_dim * (2 if bidirectional else 1), 1) # sigmoid\n","        # self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n","        self.fc = nn.Linear(hidden_dim * (2 if bidirectional else 1), 1)\n","        #self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, input_ids, attention_mask, token_index):\n","        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        sequence_output = bert_output['last_hidden_state']\n","        lstm_output, (hidden, _) = self.lstm(sequence_output)\n","\n","        if self.lstm.bidirectional:\n","            hidden = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n","            # hidden = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=-1)\n","        else:\n","            hidden = hidden[-1, :, :]\n","        # pooled_output = lstm_output[:, -1]\n","\n","        # Get the hidden state of the word at the specified index\n","        # focused_word_hidden = bilstm_output[:, word_index, :] # not this\n","        assert lstm_output.size(0) == len(input_ids)\n","        assert lstm_output.size(2) == self.lstm.hidden_size * (2 if self.lstm.bidirectional else 1)\n","\n","        focused_word_hidden = torch.zeros((lstm_output.size(0), lstm_output.size(2)))\n","        for sentence_index in range(lstm_output.size(0)):\n","            focused_word_hidden[sentence_index] = lstm_output[sentence_index, token_index[sentence_index], :]\n","        classification_output = self.classifier(focused_word_hidden)\n","\n","        # dropped_output = self.dropout(pooled_output)\n","        # logits = self.classifier(dropped_output)\n","        return self.fc(self.dropout(hidden)), classification_output\n","        '''\n","        You should not apply the sigmoid function within the BertBiLSTM model\n","        if you are using nn.BCEWithLogitsLoss(), as this loss function combines\n","        the sigmoid activation and binary cross-entropy loss in a numerically stable way.\n","        '''\n"],"metadata":{"id":"AM_8-K7Vs97X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model parameters\n","num_classes = 2\n","hidden_dim = 128\n","num_layers = 2\n","bidirectional = True\n","dropout = 0.3\n","\n","# Initialize the model\n","model = BertBiLSTM(bert_model_name, num_classes, hidden_dim, num_layers, bidirectional, dropout).to(device)\n","\n","# Use this path to save the model\n","model_path = \"/content/drive/My Drive/my_MTL_PT_model.pt\"  # Choose your desired path and filename\n","\n","# Training parameters\n","num_epochs = 5\n","learning_rate = 2e-5\n","weight_decay = 1e-2\n","\n","# criterion = nn.CrossEntropyLoss()\n","criterion_1 = nn.BCEWithLogitsLoss()\n","criterion_2 = nn.BCEWithLogitsLoss()\n","# Set up the optimizer\n","# optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"],"metadata":{"id":"7uY4IotJtFMf","colab":{"base_uri":"https://localhost:8080/","height":121,"referenced_widgets":["3f59597dbb3b4676a8b5cdb4d7d59355","8aa684651f1b49558588b8cfbc7b9db7","32b1d8568b874d0aa8e20615cffe6396","e3d58ceb58b84209a47a467f6d57880f","90a50e1806784f339dfd4eb50f5d0602","1de19254249e4e849de91446906e5ca4","88e36b00cef64e6589ea3518aae925ac","2a9b40e04f334b51915118c2d3e366ee","19aca8705872400bb56e2301c904fbc2","768cca644c554686bf39fbfa7981e20e","e4bd1e3d102841d98fe44486ef1df452"]},"executionInfo":{"status":"ok","timestamp":1682975542786,"user_tz":240,"elapsed":7039,"user":{"displayName":"Liangyu Li","userId":"13176302498120902496"}},"outputId":"f207c137-51f7-479a-e8b0-80dd679208c4"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f59597dbb3b4676a8b5cdb4d7d59355"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["# Training loop\n","for epoch in range(num_epochs):\n","    print(f'Epoch {epoch + 1}/{num_epochs}:')\n","\n","    model.train()\n","    train_loss, train_correct_1, train_correct_2, train_samples = 0, 0, 0, 0\n","    for batch in tqdm(train_dataloader):\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['label'].unsqueeze(1).float().to(device)\n","        token_index = torch.clone(batch['corresponding_location']).to(device)\n","        #print(input_ids.shape)\n","        #print(token_index.shape)\n","        #print(sum(attention_mask[3])) # every time is different\n","        for sentence_index in range(len(input_ids)):\n","            if token_index[sentence_index] < 0:\n","                # No pun word\n","                token_index[sentence_index] = torch.randint(1, int(sum(attention_mask[sentence_index])) - 1, (1,))\n","            else:\n","                token_index[sentence_index] += 1 # The start of the 'input_ids' is the start ID\n","\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        logits_1, logits_2 = model(input_ids, attention_mask, token_index)\n","\n","        # Compute the loss\n","        loss_1 = criterion_1(logits_1, labels)\n","        loss_2 = criterion_2(logits_2, labels)\n","\n","        # Combine the losses\n","        joint_loss = loss_1 + loss_2\n","\n","        optimizer.step()\n","\n","        # Backward pass\n","        joint_loss.backward()\n","\n","        # Update the weights\n","        optimizer.step()\n","\n","        train_loss += joint_loss.item()\n","\n","        # Compute the number of correct predictions\n","        # preds = torch.argmax(logits, dim=1)\n","        sigmoid_1 = torch.sigmoid(logits_1.view(-1))\n","        preds_1 = (sigmoid_1 > 0.5).unsqueeze(1).float()\n","        num_correct_1 = (preds_1 == labels).sum().item()\n","        train_correct_1 += num_correct_1\n","\n","        sigmoid_2 = torch.sigmoid(logits_2.view(-1))\n","        preds_2 = (sigmoid_2 > 0.5).unsqueeze(1).float()\n","        num_correct_2 = (preds_2 == labels).sum().item()\n","        train_correct_2 += num_correct_2\n","\n","        train_samples += labels.size(0)\n","\n","    train_avg_loss = train_loss / len(train_dataloader)\n","    train_accuracy_1 = train_correct_1 / train_samples\n","    train_accuracy_2 = train_correct_2 / train_samples\n","    print(f'Training Loss: {train_avg_loss:.4f} - Training Accuracy: {train_accuracy_1:.4f} - Training Word Accuracy: {train_accuracy_2:.4f}')\n","\n","    torch.save(model, model_path) # save the entire model, including the architecture\n","    # Don't need to recreate the architecture when loading the model later.\n","    # However, the resulting file will be larger\n","\n","    # Evaluate the model on the validation set\n","    model.eval()\n","    val_loss, val_correct_1, val_correct_2, val_samples = 0, 0, 0, 0\n","    with torch.no_grad():\n","        for batch in tqdm(val_dataloader):\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['label'].unsqueeze(1).float().to(device)\n","            token_index = torch.clone(batch['corresponding_location']).to(device)\n","            #print(input_ids.shape)\n","            for sentence_index in range(len(input_ids)):\n","                if token_index[sentence_index] < 0:\n","                    # No pun word\n","                    token_index[sentence_index] = torch.randint(1, int(sum(attention_mask[sentence_index])) - 1, (1,))\n","                else:\n","                    token_index[sentence_index] += 1 # The start of the 'input_ids' is the start ID\n","\n","            # Forward pass\n","            logits_1, logits_2 = model(input_ids, attention_mask, token_index)\n","\n","            # Compute the loss\n","            # loss = nn.CrossEntropyLoss()(logits, labels)\n","            loss_1 = criterion_1(logits_1, labels)\n","            loss_2 = criterion_2(logits_2, labels)\n","\n","            # Combine the losses\n","            joint_loss = loss_1 + loss_2\n","\n","            val_loss += joint_loss.item()\n","\n","            # Compute the number of correct predictions\n","            # preds = torch.argmax(logits, dim=1)\n","            sigmoid_1 = torch.sigmoid(logits_1.view(-1))\n","            preds_1 = (sigmoid_1 > 0.5).unsqueeze(1).float()\n","            num_correct_1 = (preds_1 == labels).sum().item()\n","            val_correct_1 += num_correct_1\n","\n","            sigmoid_2 = torch.sigmoid(logits_2.view(-1))\n","            preds_2 = (sigmoid_2 > 0.5).unsqueeze(1).float()\n","            num_correct_2 = (preds_2 == labels).sum().item()\n","            val_correct_2 += num_correct_2\n","\n","            val_samples += labels.size(0)\n","\n","    val_avg_loss = val_loss / len(val_dataloader)\n","    val_accuracy_1 = val_correct_1 / val_samples\n","    val_accuracy_2 = val_correct_2 / val_samples\n","    print(f'Validation Loss: {val_avg_loss:.4f} - Validation Accuracy: {val_accuracy_1:.4f} - Validation Word Accuracy: {val_accuracy_2:.4f}')\n"],"metadata":{"id":"gv2ZMJ5ftdb0","colab":{"base_uri":"https://localhost:8080/"},"outputId":"79f53770-6b93-426f-da93-55e7213883f4"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/5:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 144/144 [1:05:51<00:00, 27.44s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training Loss: 0.7991 - Training Accuracy: 0.8664 - Training Word Accuracy: 0.8916\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 36/36 [05:22<00:00,  8.96s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.4312 - Validation Accuracy: 0.9357 - Validation Word Accuracy: 0.9340\n","Epoch 2/5:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 144/144 [1:05:12<00:00, 27.17s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training Loss: 0.3341 - Training Accuracy: 0.9542 - Training Word Accuracy: 0.9531\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 36/36 [05:18<00:00,  8.84s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.3452 - Validation Accuracy: 0.9409 - Validation Word Accuracy: 0.9453\n","Epoch 3/5:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 144/144 [1:05:24<00:00, 27.26s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training Loss: 0.1991 - Training Accuracy: 0.9744 - Training Word Accuracy: 0.9776\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 36/36 [05:19<00:00,  8.88s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.3393 - Validation Accuracy: 0.9392 - Validation Word Accuracy: 0.9409\n","Epoch 4/5:\n"]},{"output_type":"stream","name":"stderr","text":["  5%|▍         | 7/144 [03:11<1:02:51, 27.53s/it]"]}]},{"cell_type":"code","source":["# Load the the saved file\n","loaded_model = torch.load(model_path)\n","\n","# Set the model to evaluation mode if you plan to use it for inference\n","loaded_model.eval()\n","\n","with torch.no_grad():\n","    num_correct, num_samples, num_accuracy = 0, 0, 0\n","    for ele in tqdm(val_dataset):\n","        input_ids = ele['input_ids'].reshape(1, max_length).to(device)\n","        attention_mask = ele['attention_mask'].reshape(1, max_length).to(device)\n","        #labels = ele['label'].unsqueeze(1).float().to(device)\n","        label = ele['label'].to(device)\n","        token_index = torch.clone(ele['corresponding_location']).to(device)\n","\n","        #print(input_ids)\n","        #print(attention_mask)\n","        #print(label)\n","        #print(token_index)\n","\n","        if label < 0.5:\n","            # This has not pun, do not count\n","            continue\n","        \n","        scores_list = np.zeros((int(sum(attention_mask[0])) - 2,), dtype=float)\n","        for used_token_index in range(1, int(sum(attention_mask[0])) - 1):\n","            logits_1, logits_2 = loaded_model(input_ids, attention_mask, torch.tensor(used_token_index).reshape(1,))\n","            #print(logits_2)\n","            #print(logits_2.view(-1))\n","            scores_list[used_token_index - 1] = float(torch.sigmoid(logits_2.view(-1))) # Get each ID scores\n","            #print(float(torch.sigmoid(logits_2.view(-1))))\n","\n","        # TODO: If the matched token ID is belonged to the pun word, it is also correct.\n","        if np.argmax(scores_list, axis=0) == int(token_index):\n","            num_correct += 1\n","        \n","        num_samples += 1\n","        #if num_samples == 300:\n","        #    break\n","\n","    num_accuracy = num_correct / num_samples\n","    print(f'Location Accuracy: {num_accuracy:.4f}')"],"metadata":{"id":"RTDUEBDGtkcs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682979146638,"user_tz":240,"elapsed":1723846,"user":{"displayName":"Liangyu Li","userId":"13176302498120902496"}},"outputId":"180a81be-1e91-41a9-ee6d-6f8e4d7c9557"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":[" 52%|█████▏    | 597/1151 [28:40<26:36,  2.88s/it]"]},{"output_type":"stream","name":"stdout","text":["Location Accuracy: 0.2800\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}