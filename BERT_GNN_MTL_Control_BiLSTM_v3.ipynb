{"cells":[{"cell_type":"markdown","metadata":{"id":"jDAHp7MPmYkl"},"source":["# Install and Import Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47407,"status":"ok","timestamp":1683336899060,"user":{"displayName":"Liangyu Li","userId":"13176302498120902496"},"user_tz":240},"id":"OyOMOATLlCUs","outputId":"6d6868d6-d899-47a6-af24-e750b1eb186d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://pytorch-geometric.com/whl/torch-2.0.0+cu118.html\n","Requirement already satisfied: torch-scatter in /usr/local/lib/python3.10/dist-packages (2.1.1+pt20cu118)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://pytorch-geometric.com/whl/torch-2.0.0+cu118.html\n","Requirement already satisfied: torch-sparse in /usr/local/lib/python3.10/dist-packages (0.6.17+pt20cu118)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.10.1)\n","Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.22.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://pytorch-geometric.com/whl/torch-2.0.0+cu118.html\n","Requirement already satisfied: torch-cluster in /usr/local/lib/python3.10/dist-packages (1.6.1+pt20cu118)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-cluster) (1.10.1)\n","Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-cluster) (1.22.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://pytorch-geometric.com/whl/torch-2.0.0+cu118.html\n","Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.10/dist-packages (1.2.2+pt20cu118)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.3.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.27.1)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.0.9)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.65.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.10.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n","2023-05-06 01:34:50.126366: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting en-core-web-sm==3.5.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.5.0) (3.5.2)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.27.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.7.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.22.4)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n"]}],"source":["!pip install transformers\n","!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-2.0.0+cu118.html\n","!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-2.0.0+cu118.html\n","!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-2.0.0+cu118.html\n","!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-2.0.0+cu118.html\n","# The same as Torch version and CUDA version (torch.__version__ is 2.0.0+cu118)\n","!pip install torch-geometric\n","!python3 -m spacy download en_core_web_sm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1425,"status":"ok","timestamp":1683336900481,"user":{"displayName":"Liangyu Li","userId":"13176302498120902496"},"user_tz":240},"id":"AvK4NZGBltC2","outputId":"102c0ae8-664d-4c39-e60d-6fe7279bd4b0"},"outputs":[{"name":"stdout","output_type":"stream","text":["2.0.0+cu118\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset\n","print(torch.__version__)\n","from torch_geometric.nn import GCNConv, global_mean_pool, global_max_pool\n","from torch_geometric.data import Data, DataLoader\n","from transformers import BertModel, BertTokenizer, BertConfig\n","import csv\n","#import spacy\n","import networkx as nx\n","#from gensim.models import Word2Vec\n","from tqdm import tqdm\n","import xml.etree.ElementTree as ET\n","#from nltk.corpus import wordnet as wn\n","#from nltk.corpus.reader.wordnet import Synset\n","#from nltk.wsd import lesk\n","#import nltk\n","import pickle\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","#nltk.download('wordnet')\n","#nltk.download('punkt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OuCaASlnTGzV"},"outputs":[],"source":["#nlp = spacy.load('en_core_web_sm') # DO NOT split a sentence for more 1 time\n","# If spliting a sentence more than 1 time, the result may different from the same split\n","model_path = \"/content/drive/My Drive/my_GNN_MTL_PT_model_v3.pt\"  # Choose your desired path and filename\n","# Model parameters\n","bert_model_name = 'bert-base-uncased'\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KkZjYosGLkpn"},"outputs":[],"source":["# Custom GNN and BiLSTM layers\n","class GNN(torch.nn.Module):\n","\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        # input_dim is number of features of each node\n","        super(GNN, self).__init__()\n","        self.conv1 = GCNConv(input_dim, hidden_dim)\n","        self.conv2 = GCNConv(hidden_dim, output_dim)\n","\n","    def forward(self, x, edge_index, edge_weight, batch):\n","        x = self.conv1(x, edge_index, edge_weight)\n","        x = F.relu(x)\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.conv2(x, edge_index, edge_weight)\n","\n","        # Global Pooling (stack different aggregations)\n","        hidden = torch.cat([global_mean_pool(x, batch),\n","                            global_max_pool(x, batch)], dim=1)\n","        return x, hidden\n","\n","\n","class BERT_GNN_MTL_Classifier(nn.Module):\n","    def __init__(self, num_classes, hidden_dim, num_lstm_layers, gnn_hidden_dim, gnn_output_dim, dropout, max_length, batch_size):\n","        super().__init__()\n","        self.max_length = max_length\n","        self.batch_size = batch_size\n","        self.gnn_output_dim = gnn_output_dim\n","        self.bert_config = BertConfig.from_pretrained(bert_model_name)\n","        self.bert = BertModel.from_pretrained(bert_model_name, config=self.bert_config)\n","        # Embedding size of BERT is 768\n","        self.gnn = GNN(self.bert_config.hidden_size, gnn_hidden_dim, gnn_output_dim)\n","        #self.bilstm = BiLSTM(self.bert_config.hidden_size, hidden_dim, num_lstm_layers)\n","        #self.bilstm = BiLSTM(gnn_output_dim, hidden_dim, num_lstm_layers)\n","        self.bilstm = nn.LSTM(\n","            input_size=gnn_output_dim,\n","            hidden_size=hidden_dim,\n","            num_layers=num_lstm_layers,\n","            bidirectional=True,\n","            batch_first=True,\n","            #dropout=dropout if num_layers > 1 else 0\n","        )\n","        self.bilstm_2 = nn.LSTM(\n","            input_size=self.bert.config.hidden_size,\n","            hidden_size=hidden_dim,\n","            num_layers=num_lstm_layers,\n","            bidirectional=True,\n","            batch_first=True,\n","            dropout=dropout if num_lstm_layers > 1 else 0\n","        )\n","        self.dropout = nn.Dropout(dropout)\n","        self.fc = nn.Linear(hidden_dim * 2, 1) # 2 is bidirectional LSTM, has 2, 1 is the output\n","        # self.fc = nn.Linear(hidden_dim * 2, num_classes) # multi-class classfication\n","        # self.sigmoid = nn.Sigmoid()\n","        #self.classifier = nn.Linear(hidden_dim * (2 if self.bilstm.bidirectional else 1), 1) # sigmoid\n","        self.fc2 = nn.Linear(gnn_output_dim * 2 + hidden_dim * 2, 256)\n","        self.classifier2 = nn.Linear(hidden_dim * (2 if self.bilstm.bidirectional else 1) + 256, 1) # sigmoid\n","\n","    def forward(self, data, token_index):\n","        # token_index[i] should be start with 0 and step is 1, because the GNN use only one id per word\n","        input_ids, attention_mask = data.input_ids, data.attention_mask\n","        corresponding_index, sentence_len = data.corresponding, data.sentence_len\n","        edge_index, edge_weight, num_nodes, batch = data.edge_index, data.edge_weight, data.num_nodes, data.batch\n","        #print(sentence_len)\n","        assert sum(sentence_len) == len(corresponding_index)\n","        actual_batch_size = len(input_ids) // self.max_length\n","\n","        first_cut = 0\n","        corres = [] # the corresponding index of each sentence\n","        # print(corresponding_index)\n","        # print(sentence_len)\n","        for each_sent_len_i in range(len(sentence_len) - 1):\n","            corres.append(corresponding_index[first_cut:first_cut+sentence_len[each_sent_len_i]])\n","            first_cut += sentence_len[each_sent_len_i]\n","        corres.append(corresponding_index[first_cut:first_cut+sentence_len[-1]])\n","        # print(corres)\n","        assert len(corres) == actual_batch_size\n","\n","        input_ids = torch.reshape(input_ids, (actual_batch_size, self.max_length))\n","        attention_mask = torch.reshape(attention_mask, (actual_batch_size, self.max_length))\n","        # print(\"input_ids.shape:\", input_ids.shape) # torch.Size([self.batch_size, self.max_length])\n","\n","        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","\n","        hidden_states = bert_output.last_hidden_state\n","        # print(\"hidden_states.shape:\", hidden_states.shape) # torch.Size([self.batch_size, self.max_length, 768])\n","\n","        gnn_input = torch.zeros((len(corresponding_index), hidden_states.shape[-1])) # not include the start and end ID\n","        each_batch_index = 0\n","        start_index = 0\n","        each_counter = 0\n","        # print(corresponding_index)\n","        for each_corr_i in corresponding_index:\n","            # each_corr_i + 1 because the input_ids has a start ID in the front,\n","            # which needs to add 1 to match the index\n","            gnn_input[start_index] = hidden_states[each_batch_index, each_corr_i + 1]\n","            start_index += 1\n","            each_counter += 1\n","            if each_counter == sentence_len[each_batch_index]:\n","                each_batch_index += 1\n","                each_counter = 0\n","        each_counter = 0\n","        assert each_batch_index == actual_batch_size\n","        assert start_index == len(corresponding_index)\n","        \n","        gnn_output, gnn_hidden = self.gnn(x=gnn_input, edge_index=edge_index, edge_weight=edge_weight, batch=batch)\n","        #print(gnn_hidden.shape)\n","\n","        bilstm_input = torch.zeros((actual_batch_size, self.max_length, self.gnn_output_dim))\n","        each_batch_index = 0\n","        start_index = 0\n","        # Similar to padding 0\n","        for each_sen_len in sentence_len:\n","            for each_word_i in range(each_sen_len):\n","                bilstm_input[each_batch_index, each_word_i] = gnn_output[start_index]\n","                start_index += 1\n","            each_batch_index += 1\n","\n","        each_batch_index = 0\n","        start_index = 0\n","\n","        lstm_output, (hidden, _) = self.bilstm(bilstm_input)\n","        '''\n","        Anthor way is using only last hidden state of the LSTM cell:\n","\n","        Using lstm_output[:, -1] selects the last hidden state of the LSTM cell\n","        for each sequence in the batch. The reason we use this approach in the\n","        example provided is that the last hidden state is often a good\n","        representation of the entire sequence in many sequence-to-sequence\n","        models, especially for classification tasks.\n","\n","        When we use lstm_output[:, -1], we're selecting the hidden states of the\n","        LSTM cells at the last time step (i.e., the last token in the input sequence)\n","        for each sequence in the batch. This can be a good representation of the\n","        entire sequence for classification tasks since it captures information\n","        from both the forward and backward passes of the sequence.\n","        '''\n","        pooled_output = torch.mean(lstm_output, 1)\n","\n","        if self.bilstm.bidirectional:\n","            hidden = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n","            # hidden = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=-1)\n","        else:\n","            hidden = hidden[-1, :, :]\n","\n","        #print(hidden.shape)\n","        hidden_gnn_bilstm = torch.cat([gnn_hidden, hidden], dim=-1)\n","        #print(hidden_gnn_bilstm.shape)\n","        connected_layer = self.fc2(self.dropout(hidden_gnn_bilstm))\n","        #print(\"connected_layer.shape\", connected_layer.shape)\n","\n","        # Get the hidden state of the word at the specified index\n","        assert lstm_output.size(0) == len(input_ids)\n","        assert actual_batch_size == lstm_output.size(0)\n","        assert lstm_output.size(2) == self.bilstm.hidden_size * (2 if self.bilstm.bidirectional else 1)\n","\n","        lstm_output_2, (hidden_2, _) = self.bilstm_2(hidden_states)\n","\n","        assert lstm_output_2.size(2) == self.bilstm_2.hidden_size * (2 if self.bilstm_2.bidirectional else 1)\n","\n","        focused_word_hidden = torch.zeros((lstm_output_2.size(0), lstm_output_2.size(2)))\n","        for sentence_index in range(lstm_output_2.size(0)):\n","            focused_word_hidden[sentence_index] = lstm_output_2[sentence_index, token_index[sentence_index], :]\n","        #classification_output = self.classifier(focused_word_hidden)\n","        classification_output = self.classifier2(torch.cat([focused_word_hidden, connected_layer], dim=-1))\n","\n","        return self.fc(pooled_output), classification_output\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0G6CPm3s26gw"},"outputs":[],"source":["# **sigmoid**\n","# If using sigmoid, we should use this accuracy function\n","def calculate_accuracy(output, target):\n","    assert output.shape == target.shape\n","    threshold = 0.5\n","    predictions = (output > threshold).float()\n","    correct = (predictions == target).sum().item()\n","    total = target.numel()\n","    return correct / total\n","\n","def train_epoch(model, data_loader, loss_fn_1, loss_fn_2, optimizer, device):\n","    model.train()\n","    total_loss = 0.0\n","    total_accuracy_1 = 0.0\n","    total_accuracy_2 = 0.0\n","    for batch in tqdm(data_loader):\n","        batch = batch.to(device)\n","        labels = batch.y.unsqueeze(1).float().to(device)\n","\n","        corresponding_token_index = torch.clone(batch.corresponding_location).to(device)\n","\n","        batch_att = torch.reshape(batch.attention_mask, (len(labels), len(batch.attention_mask) // len(labels)))\n","\n","        for sentence_index in range(len(labels)):\n","            if corresponding_token_index[sentence_index] < 0:\n","                # No pun word\n","                assert labels[sentence_index][0] < 0.5\n","                corresponding_token_index[sentence_index] = torch.randint(1, int(sum(batch_att[sentence_index])) - 1, (1,))\n","            else:\n","                corresponding_token_index[sentence_index] += 1 # the BERT has start ID\n","        # print(corresponding_token_index)\n","        # print(batch.id_range)\n","\n","        optimizer.zero_grad()\n","        logits_1, logits_2 = model(batch, corresponding_token_index)\n","        loss_1 = loss_fn_1(logits_1, labels)\n","        loss_2 = loss_fn_2(logits_2, labels)\n","        joint_loss = loss_1 + loss_2\n","        joint_loss.backward()\n","        optimizer.step()\n","\n","        total_loss += joint_loss.item()\n","        sigmoid_1 = torch.sigmoid(logits_1.view(-1)).unsqueeze(1)\n","        sigmoid_2 = torch.sigmoid(logits_2.view(-1)).unsqueeze(1)\n","        total_accuracy_1 += calculate_accuracy(sigmoid_1, labels)\n","        total_accuracy_2 += calculate_accuracy(sigmoid_2, labels)\n","        #print(f\"Train Loss: {total_loss:.4f}, Train Accuracy: {total_accuracy:.4f}\")\n","\n","    return total_loss / len(data_loader), total_accuracy_1 / len(data_loader), total_accuracy_2 / len(data_loader)\n","\n","\n","def eval_epoch(model, data_loader, loss_fn_1, loss_fn_2, device):\n","    model.eval()\n","    total_loss = 0.0\n","    total_accuracy_1 = 0.0\n","    total_accuracy_2 = 0.0\n","    with torch.no_grad():\n","        for batch in tqdm(data_loader):\n","            batch = batch.to(device)\n","            labels = batch.y.unsqueeze(1).float().to(device)\n","\n","            corresponding_token_index = torch.clone(batch.corresponding_location).to(device)\n","\n","            batch_att = torch.reshape(batch.attention_mask, (len(labels), len(batch.attention_mask) // len(labels)))\n","\n","            for sentence_index in range(len(labels)):\n","                if corresponding_token_index[sentence_index] < 0:\n","                    # No pun word\n","                    assert labels[sentence_index][0] < 0.5\n","                    corresponding_token_index[sentence_index] = torch.randint(1, int(sum(batch_att[sentence_index])) - 1, (1,))\n","                    # random select one location\n","                else:\n","                    corresponding_token_index[sentence_index] += 1  # the BERT has start ID\n","\n","            logits_1, logits_2 = model(batch, corresponding_token_index)\n","            loss_1 = loss_fn_1(logits_1, labels)\n","            loss_2 = loss_fn_2(logits_2, labels)\n","            joint_loss = loss_1 + loss_2\n","\n","            total_loss += joint_loss.item()\n","            sigmoid_1 = torch.sigmoid(logits_1.view(-1)).unsqueeze(1)\n","            sigmoid_2 = torch.sigmoid(logits_2.view(-1)).unsqueeze(1)\n","            total_accuracy_1 += calculate_accuracy(sigmoid_1, labels)\n","            total_accuracy_2 += calculate_accuracy(sigmoid_2, labels)\n","            #print(f\"Validation Loss: {total_loss:.4f}, Validation Accuracy: {total_accuracy:.4f}\")\n","\n","    return total_loss / len(data_loader), total_accuracy_1 / len(data_loader), total_accuracy_2 / len(data_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cJWjCNGkEvh3"},"outputs":[],"source":["# Assuming you have your data as lists: train_texts, train_labels, val_texts, and val_labels\n","tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n","max_length = 80  # Adjust the maximum length based on your dataset\n","batch_size = 32"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eNzHBhSfWqcK"},"outputs":[],"source":["fileObj = open('/content/drive/My Drive/train_dataset.obj', 'rb')\n","train_dataset = pickle.load(fileObj)\n","fileObj.close()\n","\n","fileObj = open('/content/drive/My Drive/val_dataset.obj', 'rb')\n","val_dataset = pickle.load(fileObj)\n","fileObj.close()\n","\n","# Create DataLoaders for each set with a batch size\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lYXz4RIzE4hv"},"outputs":[],"source":["# Initialize the custom BERT model\n","# num_classes = len(set(total_gold))  # Assuming labels are integers starting from 0\n","num_classes = 2\n","hidden_dim = 128\n","num_lstm_layers = 2\n","gnn_hidden_dim = 512\n","gnn_output_dim = 256\n","learning_rate = 2e-5\n","dropout = 0.3\n","\n","# Set up two different loss function\n","loss_fn_1 = nn.BCEWithLogitsLoss()\n","loss_fn_2 = nn.BCEWithLogitsLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4281,"status":"ok","timestamp":1683336937915,"user":{"displayName":"Liangyu Li","userId":"13176302498120902496"},"user_tz":240},"id":"MNoooAClivfb","outputId":"8d22297b-f373-47f9-df26-d67143cb98d3"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["BERT_GNN_MTL_Classifier(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (gnn): GNN(\n","    (conv1): GCNConv(768, 512)\n","    (conv2): GCNConv(512, 256)\n","  )\n","  (bilstm): LSTM(256, 128, num_layers=2, batch_first=True, bidirectional=True)\n","  (bilstm_2): LSTM(768, 128, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (fc): Linear(in_features=256, out_features=1, bias=True)\n","  (fc2): Linear(in_features=768, out_features=256, bias=True)\n","  (classifier2): Linear(in_features=512, out_features=1, bias=True)\n",")\n"]}],"source":["# Build the model\n","model = BERT_GNN_MTL_Classifier(num_classes, hidden_dim, num_lstm_layers,\n","                                gnn_hidden_dim, gnn_output_dim, dropout,\n","                                max_length, batch_size).to(device)\n","print(model)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ihn7ANfMFPEb","outputId":"f71a9d5d-b06f-4b7d-d1f3-fc3b33563af4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 144/144 [1:05:36<00:00, 27.34s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Training Loss: 0.9755, Training Accuracy: 0.7357, Training Word Accuracy: 0.8622\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 36/36 [04:59<00:00,  8.32s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 0.6974, Validation Accuracy: 0.9382, Validation Word Accuracy: 0.9374\n","Epoch 2/5\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 144/144 [1:00:11<00:00, 25.08s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Training Loss: 0.5620, Training Accuracy: 0.9516, Training Word Accuracy: 0.9536\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 36/36 [04:39<00:00,  7.75s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 0.5066, Validation Accuracy: 0.9339, Validation Word Accuracy: 0.9339\n","Epoch 3/5\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 144/144 [59:52<00:00, 24.95s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Training Loss: 0.2945, Training Accuracy: 0.9748, Training Word Accuracy: 0.9759\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 36/36 [04:49<00:00,  8.05s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 0.3799, Validation Accuracy: 0.9357, Validation Word Accuracy: 0.9435\n","Epoch 4/5\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 144/144 [1:02:18<00:00, 25.96s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Training Loss: 0.1810, Training Accuracy: 0.9748, Training Word Accuracy: 0.9770\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 36/36 [04:56<00:00,  8.25s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 0.4566, Validation Accuracy: 0.9313, Validation Word Accuracy: 0.9313\n","Epoch 5/5\n"]},{"name":"stderr","output_type":"stream","text":[" 49%|████▊     | 70/144 [30:37<32:24, 26.27s/it]"]}],"source":["# Train the model\n","num_epochs = 5\n","\n","for epoch in range(num_epochs):\n","    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n","    train_loss, train_acc_1, train_acc_2 = train_epoch(model, train_loader, loss_fn_1, loss_fn_2, optimizer, device)\n","    print(f\"Training Loss: {train_loss:.4f}, Training Accuracy: {train_acc_1:.4f}, Training Word Accuracy: {train_acc_2:.4f}\")\n","    torch.save(model, model_path[:-3] + '_epoch_' + str(epoch) + '.pt') # save the entire model, including the architecture\n","    val_loss, val_acc_1, val_acc_2 = eval_epoch(model, val_loader, loss_fn_1, loss_fn_2, device)\n","    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc_1:.4f}, Validation Word Accuracy: {val_acc_2:.4f}\")\n","print(\"Training complete.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"L0G90vuAriUe","outputId":"ca25e2fa-b0df-4ea4-b210-3815d89c52b6"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1151/1151 [55:06<00:00,  2.87s/it]"]},{"name":"stdout","output_type":"stream","text":["Location Accuracy: 0.5115\n","Homographic Location Accuracy: 0.4822\n","Heterographic Location Accuracy: 0.5465\n","\n","              precision    recall  f1-score   support\n","\n","     No Puns       0.97      0.93      0.95       309\n"," Homographic       0.93      0.97      0.95       309\n","\n","    accuracy                           0.95       618\n","   macro avg       0.95      0.95      0.95       618\n","weighted avg       0.95      0.95      0.95       618\n","\n","[[286  23]\n"," [  8 301]]\n","\n","               precision    recall  f1-score   support\n","\n","      No Puns       0.95      0.92      0.93       258\n","Heterographic       0.92      0.95      0.94       258\n","\n","     accuracy                           0.93       516\n","    macro avg       0.93      0.93      0.93       516\n"," weighted avg       0.93      0.93      0.93       516\n","\n","[[237  21]\n"," [ 13 245]]\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Load the the saved file\n","loaded_model = torch.load(\"/content/drive/My Drive/my_GNN_MTL_PT_model_v3_epoch_4.pt\").to(device)\n","\n","# Set the model to evaluation mode if you plan to use it for inference\n","loaded_model.eval()\n","\n","location_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n","\n","with torch.no_grad():\n","\n","    y_true_hom = []\n","    y_pred_hom = []\n","    y_true_het = []\n","    y_pred_het = []\n","    y_true_neg = []\n","    y_pred_neg = []\n","\n","    location_hom_correct = 0\n","    location_het_correct = 0\n","\n","    num_correct, num_samples, num_accuracy = 0, 0, 0\n","    for ele in tqdm(location_loader):\n","        # print(ele.attention_mask)\n","        attention_mask = ele.attention_mask.reshape(1, max_length).to(device)\n","        #labels = ele['label'].unsqueeze(1).float().to(device)\n","        label = ele.y.to(device)\n","        # corresponding_token_index = torch.clone(ele.corresponding_location).to(device)\n","        token_index = torch.clone(ele.location).to(device) # After GNN, the same as original, start with 0\n","        id_range = ele.id_range.to(device)\n","        data_identification = ele.data_identification.to(device)\n","\n","        #print(input_ids)\n","        #print(attention_mask)\n","        #print(label[0])\n","        #print(int(token_index[0]))\n","        #print(id_range)\n","        #print(ele)\n","\n","        if float(label[0]) < 0.5:\n","            y_true_neg.append(0)\n","            # This has not pun, do not count\n","            logits_1, _ = loaded_model(ele, torch.tensor(0).reshape(1,))\n","            y_pred_neg.append(0 if float(torch.sigmoid(logits_1.view(-1))) < 0.5 else 1)\n","            continue\n","        \n","        scores_list = torch.zeros((int(sum(attention_mask[0])) - 2,))\n","        for used_token_index in range(1, int(sum(attention_mask[0])) - 1):\n","            # After GNN, the index is same as original, start with 0\n","            logits_1, logits_2 = loaded_model(ele, torch.tensor(used_token_index).reshape(1,))\n","            scores_list[used_token_index - 1] = float(torch.sigmoid(logits_2.view(-1))) # Get each ID scores\n","\n","        # If the matched token ID is belonged to the pun word, it is also correct.\n","        if int(id_range[int(token_index[0])][0]) <= int(torch.argmax(scores_list, dim=0)) < int(id_range[int(token_index[0])][1]):\n","            num_correct += 1\n","\n","            if int(data_identification[0]) < 2250:\n","                location_hom_correct += 1\n","            elif 2250 <= int(data_identification[0]) < 2250 + 1780:\n","                location_het_correct += 1\n","            else:\n","                print(\"Something Wrong\")\n","        \n","        if int(data_identification[0]) < 2250:\n","            y_true_hom.append(1)\n","            y_pred_hom.append(0 if float(torch.sigmoid(logits_1.view(-1))) < 0.5 else 1)\n","        elif 2250 <= int(data_identification[0]) < 2250 + 1780:\n","            y_true_het.append(1)\n","            y_pred_het.append(0 if float(torch.sigmoid(logits_1.view(-1))) < 0.5 else 1)\n","        else:\n","            print(\"Something Wrong\")\n","\n","        num_samples += 1\n","        #if num_samples == 300:\n","        #    break\n","\n","    num_accuracy = num_correct / num_samples\n","    print(f'Location Accuracy: {num_accuracy:.4f}')\n","    print(f'Homographic Location Accuracy: {(location_hom_correct / len(y_true_hom)):.4f}')\n","    print(f'Heterographic Location Accuracy: {(location_het_correct / len(y_true_het)):.4f}')\n","    assert len(y_true_hom) + len(y_true_het) == num_samples\n","    print()\n","    print(classification_report(y_true_hom+y_true_neg[:len(y_true_hom)], y_pred_hom+y_pred_neg[:len(y_true_hom)], target_names=['No Puns', 'Homographic']))\n","    print(confusion_matrix(y_true_hom+y_true_neg[:len(y_true_hom)], y_pred_hom+y_pred_neg[:len(y_true_hom)]))\n","    print()\n","    print(classification_report(y_true_het+y_true_neg[:len(y_true_het)], y_pred_het+y_pred_neg[:len(y_true_het)], target_names=['No Puns', 'Heterographic']))\n","    print(confusion_matrix(y_true_het+y_true_neg[:len(y_true_het)], y_pred_het+y_pred_neg[:len(y_true_het)]))"]}],"metadata":{"colab":{"provenance":[{"file_id":"1sOSBkFyyPdBx8zJyRGqEOPR5t__4-ujI","timestamp":1683240416284}],"authorship_tag":"ABX9TyMBKy7nqlEgznobfA53/TkA"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}